# app.py
import os
import streamlit as st
import requests
import json
import time
import re
from typing import List, Dict
from bs4 import BeautifulSoup
from db_models import ChatDatabase
from utils import generate_conversation_title, get_export_path, format_timestamp

# è·å–ç¯å¢ƒå˜é‡ä¸­çš„ OLLAMA_HOSTï¼Œé»˜è®¤ä¸º localhost
DEFAULT_OLLAMA_HOST = os.getenv('OLLAMA_HOST', 'localhost')

# ä¿®æ”¹åˆå§‹åŒ–æœåŠ¡å™¨URLçš„éƒ¨åˆ†
if "server_url" not in st.session_state:
    st.session_state.server_url = f"{DEFAULT_OLLAMA_HOST}:11434"
# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="Ollama Chat",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []
if "current_model" not in st.session_state:
    st.session_state.current_model = None
if "server_url" not in st.session_state:
    st.session_state.server_url = "localhost:11434"
if "db" not in st.session_state:
    st.session_state.db = ChatDatabase()
if "current_conversation_id" not in st.session_state:
    st.session_state.current_conversation_id = None

def convert_svg_to_html(svg_code: str) -> str:
    """å°†SVGä»£ç è½¬æ¢ä¸ºHTMLæ˜¾ç¤ºæ ¼å¼"""
    try:
        soup = BeautifulSoup(svg_code, 'xml')
        svg = soup.find('svg')
        if svg:
            if not svg.get('viewBox'):
                width = svg.get('width', '800')
                height = svg.get('height', '600')
                svg['viewBox'] = f"0 0 {width} {height}"
            return f'<div class="rendered-svg" style="background-color: white; padding: 10px; border-radius: 5px; margin: 10px 0;">{str(svg)}</div>'
    except Exception:
        pass
    return svg_code

def process_code_blocks(text: str) -> str:
    """å¤„ç†ä»£ç å—ä¸­çš„SVG"""
    def replace_svg_in_block(match):
        code_block = match.group(1)
        if code_block.strip().startswith('<svg') and code_block.strip().endswith('</svg>'):
            return convert_svg_to_html(code_block)
        return f"```{code_block}```"

    text = re.sub(r'```(?:svg|xml)\s*([\s\S]*?)```', replace_svg_in_block, text)
    text = re.sub(r'```([\s\S]*?)```', replace_svg_in_block, text)
    return text

def process_inline_svg(text: str) -> str:
    """å¤„ç†è¡Œå†…SVGæ ‡ç­¾"""
    def replace_svg(match):
        return convert_svg_to_html(match.group(0))
    return re.sub(r'<svg[\s\S]*?</svg>', replace_svg, text)

def process_message(text: str) -> str:
    """å¤„ç†æ¶ˆæ¯ä¸­çš„æ‰€æœ‰SVGå†…å®¹"""
    text = process_code_blocks(text)
    text = process_inline_svg(text)
    return text

def get_models() -> List[str]:
    """è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    try:
        response = requests.get(f"http://{st.session_state.server_url}/api/tags")
        response.raise_for_status()
        models = response.json().get("models", [])
        return [model["name"] for model in models]
    except requests.exceptions.RequestException as e:
        st.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {str(e)}")
        return []

def send_message(message: str, history: List[Dict], model: str):
    """å‘é€æ¶ˆæ¯åˆ° Ollama API å¹¶è·å–å“åº”"""
    url = f"http://{st.session_state.server_url}/api/chat"
    messages = [{"role": msg["role"], "content": msg["content"]} for msg in history]
    messages.append({"role": "user", "content": message})
    
    try:
        response = requests.post(
            url,
            json={
                "model": model,
                "messages": messages,
                "stream": True
            },
            stream=True,
            timeout=60
        )
        response.raise_for_status()
        
        full_response = ""
        for line in response.iter_lines():
            if line:
                try:
                    json_response = json.loads(line)
                    if "message" in json_response and "content" in json_response["message"]:
                        chunk = json_response["message"]["content"]
                        full_response += chunk
                        processed_response = process_message(full_response)
                        yield processed_response, False
                except json.JSONDecodeError:
                    continue
        
        final_response = process_message(full_response)
        yield final_response, True
                
    except requests.exceptions.RequestException as e:
        st.error(f"å‘é€æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
        yield None, True

def start_new_conversation():
    """å¼€å§‹æ–°å¯¹è¯"""
    st.session_state.messages = []
    st.session_state.current_conversation_id = None
    st.rerun()

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ’¬ èŠå¤©è®¾ç½®")
    
    # æœåŠ¡å™¨URLè®¾ç½®
    server_url = st.text_input(
        "æœåŠ¡å™¨åœ°å€",
        value=st.session_state.server_url,
        help="è¾“å…¥ Ollama æœåŠ¡å™¨åœ°å€ï¼Œæ ¼å¼å¦‚: localhost:11434"
    )
    
    if server_url != st.session_state.server_url:
        st.session_state.server_url = server_url
        st.session_state.current_model = None
        st.rerun()
    
    # æ¨¡å‹é€‰æ‹©
    available_models = get_models()
    if available_models:
        if st.session_state.current_model is None:
            st.session_state.current_model = available_models[0]
        
        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            available_models,
            index=available_models.index(st.session_state.current_model)
        )
        
        if selected_model != st.session_state.current_model:
            st.session_state.current_model = selected_model
            start_new_conversation()
    else:
        st.error("æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨åœ°å€æ˜¯å¦æ­£ç¡®")
    
    # å†å²å¯¹è¯
    st.markdown("---")
    st.subheader("ğŸ“š å†å²å¯¹è¯")
    
    # æ–°å¯¹è¯æŒ‰é’®
    if st.button("â• æ–°å¯¹è¯"):
        start_new_conversation()
    
    # æ˜¾ç¤ºå†å²å¯¹è¯åˆ—è¡¨
    conversations = st.session_state.db.get_all_conversations()
    for conv_id, title, model, created_at in conversations:
        col1, col2 = st.columns([4, 1])
        with col1:
            if st.button(f"ğŸ“ {title}", key=f"conv_{conv_id}"):
                conv_data = st.session_state.db.get_conversation(conv_id)
                st.session_state.messages = conv_data["messages"]
                st.session_state.current_model = conv_data["model"]
                st.session_state.current_conversation_id = conv_id
                st.rerun()
        with col2:
            if st.button("ğŸ—‘ï¸", key=f"del_{conv_id}"):
                st.session_state.db.delete_conversation(conv_id)
                if conv_id == st.session_state.current_conversation_id:
                    start_new_conversation()
                else:
                    st.rerun()
    
    # å¯¼å‡ºå½“å‰å¯¹è¯
    if st.session_state.current_conversation_id:
        st.markdown("---")
        if st.button("ğŸ’¾ å¯¼å‡ºå½“å‰å¯¹è¯"):
            export_path = get_export_path("exports", st.session_state.current_conversation_id)
            st.session_state.db.export_conversation(st.session_state.current_conversation_id, export_path)
            st.success(f"å¯¹è¯å·²å¯¼å‡ºåˆ°: {export_path}")

# ä¸»ç•Œé¢
st.title("ğŸ¤– Ollama Chat")

if not st.session_state.current_model:
    st.warning("è¯·å…ˆåœ¨å·¦ä¾§é€‰æ‹©ä¸€ä¸ªæ¨¡å‹")
else:
    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"], unsafe_allow_html=True)

    # èŠå¤©è¾“å…¥
    if prompt := st.chat_input("è¾“å…¥æ‚¨çš„æ¶ˆæ¯..."):
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # åˆ›å»ºæ–°å¯¹è¯æˆ–æ·»åŠ åˆ°ç°æœ‰å¯¹è¯
        if not st.session_state.current_conversation_id:
            title = generate_conversation_title(prompt)
            st.session_state.current_conversation_id = st.session_state.db.create_conversation(
                title, 
                st.session_state.current_model
            )
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
        st.session_state.db.add_message(
            st.session_state.current_conversation_id,
            "user",
            prompt
        )
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # æ˜¾ç¤ºåŠ©æ‰‹æ¶ˆæ¯
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            response_complete = False
            final_response = None
            
            for response_chunk, is_complete in send_message(prompt, st.session_state.messages, st.session_state.current_model):
                if response_chunk is not None:
                    message_placeholder.markdown(response_chunk + "â–Œ", unsafe_allow_html=True)
                    time.sleep(0.01)
                response_complete = is_complete
                if is_complete:
                    final_response = response_chunk
            
            if response_complete and final_response is not None:
                message_placeholder.markdown(final_response, unsafe_allow_html=True)
                # ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯
                st.session_state.db.add_message(
                    st.session_state.current_conversation_id,
                    "assistant",
                    final_response
                )
                st.session_state.messages.append({"role": "assistant", "content": final_response})
            elif not response_complete:
                message_placeholder.markdown("âŒ è·å–å“åº”å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨è¿æ¥ã€‚")

# æ·»åŠ è‡ªå®šä¹‰ CSS
st.markdown("""
<style>
    .rendered-svg {
        display: block !important;
    }
    .rendered-svg svg {
        max-width: 100%;
        height: auto;
    }
</style>
""", unsafe_allow_html=True)